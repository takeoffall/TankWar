{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=scipy.io.loadmat(\"F:\\学习\\课程学习\\认知科学基础实验\\P300 BCI Competition 2005\\\\bciIII-II\\Subject_A_Train.mat\")\n",
    "data_1=scipy.io.loadmat(\"F:\\学习\\课程学习\\认知科学基础实验\\P300 BCI Competition 2005\\\\bciIII-II\\Subject_A_Test.mat\")\n",
    "\n",
    "#时间粒度 1=4.16ms\n",
    "Date=200\n",
    "\n",
    "data_StimulusCode=data['StimulusCode']\n",
    "data_Signal=data['Signal']\n",
    "data_StimulusType=data['StimulusType']\n",
    "\n",
    "data_Signal_s = np.zeros((180 * 85, 64*4))\n",
    "data_StimulusType_s = np.zeros((180 * 85, 1))\n",
    "\n",
    "\n",
    "data_StimulusCode_t=data_1['StimulusCode']\n",
    "data_Signal_t=data_1['Signal']\n",
    "\n",
    "data_Signal_t_s = np.zeros((180 * 100, 64*4))\n",
    "test_code=np.zeros((180 * 100, 1))\n",
    "\n",
    "for i in range(data_Signal.shape[0]):\n",
    "    for j in range(180):\n",
    "        a_1 = data_Signal[i][j * (24 + 18)+ int(Date/4.16)*0:j * (24 + 18) + int(int(Date/4.16)*1), :]\n",
    "        a_2 = data_Signal[i][j * (24 + 18)+int(Date/4.16*0.8):j * (24 + 18) + int(Date/4.16*1.8), :]\n",
    "        a_3 = data_Signal[i][j * (24 + 18)+ int(Date/4.16*1.6):j * (24 + 18) + int(Date/4.16*2.6), :]\n",
    "        a_4 = data_Signal[i][j * (24 + 18)+ int(Date/4.16*2.4):j * (24 + 18) + int(Date/4.16*3.4), :]\n",
    "        b_1 = a_1.mean(axis=0).reshape([1, -1])\n",
    "        b_2 = a_2.mean(axis=0).reshape([1, -1])\n",
    "        b_3 = a_3.mean(axis=0).reshape([1, -1])\n",
    "        b_4 = a_4.mean(axis=0).reshape([1, -1])\n",
    "        data_Signal_s[i*180+j]=np.concatenate((b_1,b_2,b_3,b_4),axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        a = data_StimulusType[i:i + 1, j * (24 + 18):j * (24 + 18) + 24]\n",
    "        b = a.mean()\n",
    "        data_StimulusType_s[i*180+j] = b\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "for i in range(data_Signal_t.shape[0]):\n",
    "    for j in range(180):\n",
    "        a_1 = data_Signal_t[i][j * (24 + 18)+ int(Date/4.16)*0:j * (24 + 18) + int(int(Date/4.16)*1), :]\n",
    "        a_2 = data_Signal_t[i][j * (24 + 18)+int(Date/4.16*0.8):j * (24 + 18) + int(Date/4.16*1.8), :]\n",
    "        a_3 = data_Signal_t[i][j * (24 + 18)+ int(Date/4.16*1.6):j * (24 + 18) + int(Date/4.16*2.6), :]\n",
    "        a_4 = data_Signal_t[i][j * (24 + 18)+ int(Date/4.16*2.4):j * (24 + 18) + int(Date/4.16*3.4), :]\n",
    "        \n",
    "        \n",
    "        b_1 = a_1.mean(axis=0).reshape([1, -1])\n",
    "        b_2 = a_2.mean(axis=0).reshape([1, -1])\n",
    "        b_3 = a_3.mean(axis=0).reshape([1, -1])\n",
    "        b_4 = a_4.mean(axis=0).reshape([1, -1])\n",
    "       \n",
    "        data_Signal_t_s[i*180+j]=np.concatenate((b_1,b_2,b_3,b_4),axis=1)\n",
    "        \n",
    "        a = data_StimulusCode_t[i:i + 1, j * (24 + 18):j * (24 + 18) + 24]\n",
    "        b = a.mean()\n",
    "        test_code[i*180+j] = b\n",
    "        \n",
    "\n",
    "data_1 = np.concatenate((data_Signal_s, data_StimulusType_s), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conversion(pre_1,data_code,code):\n",
    "    pre_a=np.array(pre_1)\n",
    "    d=[]\n",
    "    MATRIX = ['abcdef',\n",
    "          'ghijkl',\n",
    "          'mnopqr',\n",
    "          'stuvwx',\n",
    "          'yz1234',\n",
    "          '56789_']\n",
    "    hang_index=[1,2,3,4,5,6]\n",
    "    lie_index=[7,8,9,10,11,12]\n",
    "    result=[]\n",
    "    true_label=\"WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU\"\n",
    "    true_label=true_label.lower()\n",
    "    print(true_label)\n",
    "    for i in range(100):\n",
    "        c={}\n",
    "        for k in range(15):\n",
    "            a=pre_a[180*i+k*12:180*i+(k+1)*12]\n",
    "            a=list(a[:,0])\n",
    "            b=sorted(a)\n",
    "            \n",
    "            index_1=a.index(b[11])\n",
    "            index_2=a.index(b[10])\n",
    "            \n",
    "            a_1=code[180*i+k*12:180*i+(k+1)*12]\n",
    "            a_1=list(a_1[:,0])\n",
    "            \n",
    "            label_1=a_1[index_1]\n",
    "            label_2=a_1[index_2]\n",
    "            \n",
    "            \n",
    "            \n",
    "            c[label_1]=c.get(label_1,0)+1\n",
    "            c[label_2]=c.get(label_2,0)+1\n",
    "        \n",
    "        dict1_sorted_values = sorted(c.items(),key = lambda x:x[1],reverse = True)\n",
    "        \n",
    "        hang=[i for i in dict1_sorted_values if i[0] in hang_index]\n",
    "        lie=[i for i in dict1_sorted_values if i[0] in lie_index]\n",
    "        \n",
    "        a=int(hang[0][0]-1)\n",
    "        b=int(lie[0][0]-7)\n",
    "        result.append(MATRIX[b][a])\n",
    "        \n",
    "    count=0\n",
    "    for i in range(len(true_label)):\n",
    "        if true_label[i]==result[i]:\n",
    "            count+=1\n",
    "    print(\"准确度：\",count/100)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lgb_model(train, test):\n",
    "    param = {\n",
    "    'num_leaves': 32,\n",
    "    'min_data_in_leaf': 20,\n",
    "    'min_child_samples':80,\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.05,\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"feature_fraction\": 0.5,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_seed\": 23,\n",
    "    \"nthread\": 8,\n",
    "    \"reg_alpha\":0.5,\n",
    "    \"reg_lambda\":1.0,\n",
    "    'metric':'auc',\n",
    "    'random_state':42}\n",
    "    label = train[:, -1]\n",
    "    train = np.delete(train, -1, axis=1)\n",
    "    train=pd.DataFrame(train)\n",
    "    test=pd.DataFrame(test)\n",
    "    \n",
    "    X=train\n",
    "    y=pd.DataFrame(label)[0]\n",
    "    \n",
    "    X_test=test\n",
    "    \n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "    \n",
    "    oof_lgb = np.zeros(len(train[i]))\n",
    "    predictions_lgb = np.zeros(len(test[i]))\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X.values, y.values)):\n",
    "            print(\"fold {}\".format(fold_))\n",
    "            X_train,y_train = X.iloc[trn_idx],y.iloc[trn_idx]\n",
    "\n",
    "          \n",
    "           \n",
    "            trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "            val_data = lgb.Dataset(X.iloc[val_idx], label=y.iloc[val_idx])\n",
    "\n",
    "            num_round = 10000\n",
    "            \n",
    "            clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=50, early_stopping_rounds = 50)\n",
    "            oof_lgb[val_idx] = clf.predict(X.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "            predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration)/5\n",
    "            \n",
    "            \n",
    "    print(\"CV Score: {:<8.5f}\".format(roc_auc_score(y, oof_lgb)))\n",
    "    \n",
    "    return pd.DataFrame(predictions_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's auc: 0.864074\tvalid_1's auc: 0.612453\n",
      "[100]\ttraining's auc: 0.948654\tvalid_1's auc: 0.628561\n",
      "[150]\ttraining's auc: 0.984451\tvalid_1's auc: 0.633909\n",
      "[200]\ttraining's auc: 0.994851\tvalid_1's auc: 0.633429\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's auc: 0.987091\tvalid_1's auc: 0.635522\n",
      "fold 1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's auc: 0.868975\tvalid_1's auc: 0.637902\n",
      "[100]\ttraining's auc: 0.955417\tvalid_1's auc: 0.637287\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.933293\tvalid_1's auc: 0.644656\n",
      "fold 2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's auc: 0.869415\tvalid_1's auc: 0.644161\n",
      "[100]\ttraining's auc: 0.954641\tvalid_1's auc: 0.645161\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's auc: 0.883053\tvalid_1's auc: 0.649539\n",
      "fold 3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's auc: 0.859613\tvalid_1's auc: 0.639647\n",
      "[100]\ttraining's auc: 0.949935\tvalid_1's auc: 0.640095\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's auc: 0.873953\tvalid_1's auc: 0.643529\n",
      "fold 4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's auc: 0.865844\tvalid_1's auc: 0.63882\n",
      "[100]\ttraining's auc: 0.953822\tvalid_1's auc: 0.64228\n",
      "[150]\ttraining's auc: 0.985685\tvalid_1's auc: 0.639953\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's auc: 0.955056\tvalid_1's auc: 0.642363\n",
      "CV Score: 0.63825 \n"
     ]
    }
   ],
   "source": [
    "pre_result = Lgb_model(data_1, data_Signal_t_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wqxplzcomrko97yfzdez1dpi9nnvgrqdjcuvrmeuooojd2ufypoo6j7ldgyegoa5vhnehbtxoo1tdoiluee5bfaeexaw_k4r3mru\n",
      "准确度： 0.53\n"
     ]
    }
   ],
   "source": [
    "Conversion(pre_result,data_StimulusCode_t,test_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xgb_model(train, test):\n",
    "    label = train[:, -1]\n",
    "    train = np.delete(train, -1, axis=1)\n",
    "\n",
    "    params = {'booster': 'gbtree',\n",
    "              'objective': 'binary:logistic',\n",
    "              'eval_metic': 'auc',\n",
    "              'silent': 1,\n",
    "              'eta': 0.05,\n",
    "              'max_depth': 3,\n",
    "              'min_child_weight': 19,\n",
    "              'gamma': 0,\n",
    "              'lamdba': 0.05,\n",
    "              'subsample': 0.88327,\n",
    "              'n_estimators': 996,\n",
    "              'scale_pos_weight': 10\n",
    "              }\n",
    "\n",
    "    y = pd.DataFrame(label)\n",
    "    train_data = pd.DataFrame(train)\n",
    "    test=pd.DataFrame(test)\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2333)\n",
    "    oof_lgb = np.zeros(len(train_data))\n",
    "    predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "    num_round = 1000\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data.values, y.values)):\n",
    "        print(fold_)\n",
    "        trn_data = xgb.DMatrix(train_data.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "        val_data = xgb.DMatrix(train_data.iloc[val_idx], label=y.iloc[val_idx])\n",
    "\n",
    "        watchlist = [(val_data, 'train')]\n",
    "        clf = xgb.train(params=params, dtrain=trn_data, num_boost_round=num_round, evals=watchlist)\n",
    "\n",
    "        oof_lgb[val_idx] = clf.predict(val_data)\n",
    "        predictions_xgb += clf.predict(xgb.DMatrix(test)) / folds.n_splits\n",
    "\n",
    "#         a = pd.DataFrame(train_data.columns)\n",
    "#         a[str(fold_) + '_imprtance'] = a[0].map(clf.get_fscore())\n",
    "\n",
    "    print(\"CV Score: {:<8.5f}\".format(roc_auc_score(y, oof_lgb)))\n",
    "\n",
    "    return pd.DataFrame(predictions_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
